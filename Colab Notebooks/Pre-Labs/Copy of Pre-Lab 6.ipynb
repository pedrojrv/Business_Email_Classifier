{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Pre-Lab 6.ipynb","version":"0.3.2","provenance":[{"file_id":"1psCrqlQEJTdtt6pLCYEEKn4jh-IdqInX","timestamp":1553547216809}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"BaEO_dsL_WAf","colab_type":"text"},"cell_type":"markdown","source":["## Gensim Tutorial"]},{"metadata":{"id":"K1B35oHx_WAh","colab_type":"text"},"cell_type":"markdown","source":["## Part A:"]},{"metadata":{"id":"GY2LYeDW_WAj","colab_type":"code","colab":{}},"cell_type":"code","source":["import nltk\n","import numpy as np\n","import gensim\n","from gensim.models import Word2Vec\n","from nltk.data import find\n","import matplotlib\n","from sklearn.manifold import TSNE\n","import string\n","from urllib.request import urlopen\n","import nltk, re, pprint\n","from nltk import word_tokenize\n","from nltk import tokenize\n","\n","## Vizualise\n","%matplotlib inline\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yg90ovm-x57Q","colab_type":"text"},"cell_type":"markdown","source":["Google’s pre-trained model here - It’s 1.5GB! It includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 features."]},{"metadata":{"id":"EFD3IenT_WA0","colab_type":"code","outputId":"efdba01d-f802-4e07-b524-eebaa840055b","executionInfo":{"status":"ok","timestamp":1553548256082,"user_tz":420,"elapsed":29897,"user":{"displayName":"Pedro Junior Vicente Valdez","photoUrl":"https://lh5.googleusercontent.com/-dmH1Mj72Wlc/AAAAAAAAAAI/AAAAAAAAAAk/dLWhjPglJRo/s64/photo.jpg","userId":"10490573767420939040"}},"colab":{"base_uri":"https://localhost:8080/","height":209}},"cell_type":"code","source":["!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-03-25 21:10:26--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.112.29\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.112.29|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1647046227 (1.5G) [application/x-gzip]\n","Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n","\n","GoogleNews-vectors- 100%[===================>]   1.53G  47.7MB/s    in 29s     \n","\n","2019-03-25 21:10:55 (54.6 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"_jCFyIAesLjl","colab_type":"code","colab":{}},"cell_type":"code","source":["from gensim.models import KeyedVectors\n","model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"631sMlAsP1zC","colab_type":"code","colab":{}},"cell_type":"code","source":["word_vectors = model.wv\n","word_vectors.vocab"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IMFgGXHA_WBG","colab_type":"code","outputId":"ee4e57ff-afa8-4ce2-cb36-3c51aacd698b","executionInfo":{"status":"ok","timestamp":1553548751750,"user_tz":420,"elapsed":398,"user":{"displayName":"Pedro Junior Vicente Valdez","photoUrl":"https://lh5.googleusercontent.com/-dmH1Mj72Wlc/AAAAAAAAAAI/AAAAAAAAAAk/dLWhjPglJRo/s64/photo.jpg","userId":"10490573767420939040"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"cell_type":"code","source":["word_pairs = [\n","              ('India', 'Pakistan') ,\n","              ('massive', 'puny'), \n","              ('California', 'Sacramento'), \n","              ('Iceland', 'volcano'), \n","              ('fast', 'faster')\n","            ]\n","for pair in word_pairs:\n","    print(model.similarity(pair[0], pair[1]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["0.6706861\n","0.33377072\n","0.6366068\n","0.3833339\n","0.5216066\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"}]},{"metadata":{"id":"zDCIy68-_WBP","colab_type":"code","outputId":"adb45420-f3da-43a6-a188-d3904db50500","executionInfo":{"status":"ok","timestamp":1553548762202,"user_tz":420,"elapsed":362,"user":{"displayName":"Pedro Junior Vicente Valdez","photoUrl":"https://lh5.googleusercontent.com/-dmH1Mj72Wlc/AAAAAAAAAAI/AAAAAAAAAAk/dLWhjPglJRo/s64/photo.jpg","userId":"10490573767420939040"}},"colab":{"base_uri":"https://localhost:8080/","height":2199}},"cell_type":"code","source":["words = ['woman', 'man']\n","for word in words:\n","  print(len(model[word]), model[word])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["300 [ 2.43164062e-01 -7.71484375e-02 -1.03027344e-01 -1.07421875e-01\n","  1.18164062e-01 -1.07421875e-01 -1.14257812e-01  2.56347656e-02\n","  1.11816406e-01  4.85839844e-02 -9.71679688e-02 -3.43750000e-01\n"," -6.29882812e-02 -1.25000000e-01 -2.70996094e-02  9.42382812e-02\n"," -1.87500000e-01 -5.34667969e-02  6.25000000e-02 -3.05175781e-02\n"," -2.90527344e-02 -4.80957031e-02 -5.51757812e-02 -4.08203125e-01\n","  1.01318359e-02 -2.32421875e-01 -1.70898438e-01  2.63671875e-01\n","  3.49609375e-01 -2.11914062e-01  1.43554688e-01 -6.22558594e-03\n"," -2.25585938e-01 -1.05468750e-01 -1.16210938e-01  1.23046875e-01\n","  3.06640625e-01 -4.88281250e-02 -9.57031250e-02  1.99218750e-01\n"," -1.57226562e-01 -2.80761719e-02  1.58203125e-01 -2.42919922e-02\n","  1.29882812e-01 -8.98437500e-02 -7.61718750e-02  3.54003906e-02\n"," -3.06396484e-02  1.52343750e-01  5.24902344e-02  1.60980225e-03\n","  5.56640625e-02  3.95507812e-02 -7.71484375e-02 -7.12890625e-02\n"," -9.22851562e-02 -7.03125000e-02  2.03125000e-01  1.53198242e-02\n","  2.98828125e-01  1.75781250e-01 -4.54101562e-02  9.52148438e-02\n","  4.12597656e-02  7.76367188e-02  9.47265625e-02  1.67968750e-01\n","  2.01171875e-01 -7.22656250e-02  1.83593750e-01  2.15820312e-01\n"," -2.38281250e-01  1.04980469e-01 -1.66015625e-02  2.40234375e-01\n","  1.67236328e-02 -4.56542969e-02  1.68945312e-01  1.85546875e-01\n","  2.47070312e-01 -1.02050781e-01  8.49609375e-02 -1.04003906e-01\n"," -4.74609375e-01  2.63671875e-01 -1.57226562e-01  8.25195312e-02\n","  2.19726562e-01 -3.03955078e-02 -2.55859375e-01 -1.97265625e-01\n"," -9.27734375e-02 -1.28173828e-02  1.26953125e-01  3.54003906e-02\n","  5.88378906e-02  3.27148438e-02  1.72851562e-01 -2.08740234e-02\n"," -1.65039062e-01 -2.81250000e-01  8.49609375e-02 -1.69921875e-01\n","  2.31445312e-01 -1.41601562e-01  7.91015625e-02 -1.92382812e-01\n","  7.61718750e-02 -2.23632812e-01 -1.06811523e-02  5.66406250e-02\n","  1.56250000e-01  7.17773438e-02 -1.56250000e-01 -1.44531250e-01\n"," -8.30078125e-02 -1.21093750e-01  5.63964844e-02  2.61718750e-01\n","  7.95898438e-02 -1.28784180e-02 -2.00195312e-01 -4.39453125e-02\n"," -1.01562500e-01  1.29882812e-01  9.42382812e-02  1.90429688e-02\n","  1.42578125e-01  1.59179688e-01 -7.47070312e-02 -3.24218750e-01\n"," -2.07031250e-01  4.80957031e-02 -4.19921875e-02  9.22851562e-02\n"," -4.39453125e-02 -2.20703125e-01 -6.25000000e-02  8.39843750e-02\n","  2.29492188e-01 -1.11816406e-01  9.03320312e-02  2.08984375e-01\n"," -2.28515625e-01  2.87109375e-01 -1.38671875e-01  1.85546875e-01\n"," -2.10937500e-01 -2.05078125e-01  3.00781250e-01 -1.82617188e-01\n","  1.23046875e-01 -1.61132812e-01  9.37500000e-02  1.25976562e-01\n"," -8.10546875e-02  9.15527344e-05  1.53320312e-01 -8.10546875e-02\n"," -1.93359375e-01  7.08007812e-03  3.84765625e-01  1.05957031e-01\n"," -1.09375000e-01 -1.13769531e-01  9.13085938e-02 -1.92382812e-01\n","  6.12792969e-02  6.07299805e-03 -4.54101562e-02  6.25000000e-02\n"," -1.30859375e-01 -1.83593750e-01 -1.76757812e-01 -1.87500000e-01\n","  2.44140625e-01  1.89453125e-01 -1.93359375e-01 -2.29492188e-02\n","  2.53906250e-02  3.93676758e-03 -1.38671875e-01 -2.81250000e-01\n"," -1.80664062e-01  8.69140625e-02  3.17382812e-02  2.55859375e-01\n"," -2.30468750e-01 -5.24902344e-02 -2.18200684e-03  1.60156250e-01\n","  1.57226562e-01  2.79296875e-01  1.37695312e-01  1.04492188e-01\n"," -1.18652344e-01 -5.81054688e-02 -7.32421875e-02  1.04980469e-02\n"," -1.77734375e-01 -1.07421875e-01 -1.76757812e-01 -1.23046875e-01\n"," -1.69921875e-01 -1.34765625e-01  6.39648438e-02  1.22558594e-01\n","  1.95312500e-01 -4.94140625e-01 -3.90625000e-02 -3.19824219e-02\n"," -1.58691406e-02 -4.10156250e-02 -1.43554688e-01 -8.59375000e-02\n"," -7.95898438e-02  2.46093750e-01 -1.77734375e-01  2.05078125e-01\n","  5.32226562e-02 -2.51464844e-02  2.14843750e-01  2.12402344e-02\n","  9.76562500e-02 -2.16796875e-01  2.85156250e-01 -1.19140625e-01\n"," -1.66992188e-01 -3.60107422e-03  4.61425781e-02 -1.63085938e-01\n"," -2.53906250e-01  1.89453125e-01 -7.51953125e-02 -5.39550781e-02\n"," -1.77734375e-01 -4.32128906e-02 -7.38525391e-03  1.57226562e-01\n","  2.53906250e-01 -1.52343750e-01 -5.27343750e-02 -1.25000000e-01\n","  1.54296875e-01  1.11816406e-01 -1.54418945e-02  8.97216797e-03\n"," -5.63964844e-02 -2.58789062e-02  1.93359375e-01  5.22460938e-02\n"," -1.56250000e-02 -5.68847656e-02  1.17187500e-01  6.00585938e-02\n"," -2.64892578e-02 -1.39648438e-01 -7.27539062e-02 -5.00488281e-02\n","  2.97851562e-02 -9.61914062e-02 -1.60156250e-01 -1.41601562e-01\n","  2.17773438e-01  2.55859375e-01 -4.58984375e-02  1.17187500e-01\n"," -2.46093750e-01 -7.27539062e-02 -8.69140625e-02  1.57226562e-01\n"," -1.88476562e-01  4.39453125e-02 -5.55419922e-03  6.93359375e-02\n","  1.42578125e-01 -1.20605469e-01 -1.04003906e-01 -3.41796875e-02\n","  1.82617188e-01 -1.29882812e-01  1.63574219e-02  3.20312500e-01\n"," -1.12304688e-01 -1.12915039e-02 -1.38671875e-01 -2.20703125e-01\n","  7.59124756e-04  3.94531250e-01  1.03515625e-01 -6.64062500e-02\n"," -2.67578125e-01 -2.47070312e-01 -7.27539062e-02  1.07910156e-01\n","  1.18652344e-01 -8.30078125e-02  6.54296875e-02 -2.94189453e-02]\n","300 [ 0.32617188  0.13085938  0.03466797 -0.08300781  0.08984375 -0.04125977\n"," -0.19824219  0.00689697  0.14355469  0.0019455   0.02880859 -0.25\n"," -0.08398438 -0.15136719 -0.10205078  0.04077148 -0.09765625  0.05932617\n","  0.02978516 -0.10058594 -0.13085938  0.001297    0.02612305 -0.27148438\n","  0.06396484 -0.19140625 -0.078125    0.25976562  0.375      -0.04541016\n","  0.16210938  0.13671875 -0.06396484 -0.02062988 -0.09667969  0.25390625\n","  0.24804688 -0.12695312  0.07177734  0.3203125   0.03149414 -0.03857422\n","  0.21191406 -0.00811768  0.22265625 -0.13476562 -0.07617188  0.01049805\n"," -0.05175781  0.03808594 -0.13378906  0.125       0.0559082  -0.18261719\n","  0.08154297 -0.08447266 -0.07763672 -0.04345703  0.08105469 -0.01092529\n","  0.17480469  0.30664062 -0.04321289 -0.01416016  0.09082031 -0.00927734\n"," -0.03442383 -0.11523438  0.12451172 -0.0246582   0.08544922  0.14355469\n"," -0.27734375  0.03662109 -0.11035156  0.13085938 -0.01721191 -0.08056641\n"," -0.00708008 -0.02954102  0.30078125 -0.09033203  0.03149414 -0.18652344\n"," -0.11181641  0.10253906 -0.25976562 -0.02209473  0.16796875 -0.05322266\n"," -0.14550781 -0.01049805 -0.03039551 -0.03857422  0.11523438 -0.0062561\n"," -0.13964844  0.08007812  0.06103516 -0.15332031 -0.11132812 -0.14160156\n","  0.19824219 -0.06933594  0.29296875 -0.16015625  0.20898438  0.00041771\n","  0.01831055 -0.20214844  0.04760742  0.05810547 -0.0123291  -0.01989746\n"," -0.00364685 -0.0135498  -0.08251953 -0.03149414  0.00717163  0.20117188\n","  0.08300781 -0.0480957  -0.26367188 -0.09667969 -0.22558594 -0.09667969\n","  0.06494141 -0.02502441  0.08496094  0.03198242 -0.07568359 -0.25390625\n"," -0.11669922 -0.01446533 -0.16015625 -0.00701904 -0.05712891  0.02807617\n"," -0.09179688  0.25195312  0.24121094  0.06640625  0.12988281  0.17089844\n"," -0.13671875  0.1875     -0.10009766 -0.04199219 -0.12011719  0.00524902\n","  0.15625    -0.203125   -0.07128906 -0.06103516  0.01635742  0.18261719\n","  0.03588867 -0.04248047  0.16796875 -0.15039062 -0.16992188  0.01831055\n","  0.27734375 -0.01269531 -0.0390625  -0.15429688  0.18457031 -0.07910156\n","  0.09033203 -0.02709961  0.08251953  0.06738281 -0.16113281 -0.19628906\n"," -0.15234375 -0.04711914  0.04760742  0.05908203 -0.16894531 -0.14941406\n","  0.12988281  0.04321289  0.02624512 -0.1796875  -0.19628906  0.06445312\n","  0.08935547  0.1640625  -0.03808594 -0.09814453 -0.01483154  0.1875\n","  0.12792969  0.22753906  0.01818848 -0.07958984 -0.11376953 -0.06933594\n"," -0.15527344 -0.08105469 -0.09277344 -0.11328125 -0.15136719 -0.08007812\n"," -0.05126953 -0.15332031  0.11669922  0.06835938  0.0324707  -0.33984375\n"," -0.08154297 -0.08349609  0.04003906  0.04907227 -0.24121094 -0.13476562\n"," -0.05932617  0.12158203 -0.34179688  0.16503906  0.06176758 -0.18164062\n","  0.20117188 -0.07714844  0.1640625   0.00402832  0.30273438 -0.10009766\n"," -0.13671875 -0.05957031  0.0625     -0.21289062 -0.06542969  0.1796875\n"," -0.07763672 -0.01928711 -0.15039062 -0.00106049  0.03417969  0.03344727\n","  0.19335938  0.01965332 -0.19921875 -0.10644531  0.01525879  0.00927734\n","  0.01416016 -0.02392578  0.05883789  0.02368164  0.125       0.04760742\n"," -0.05566406  0.11572266  0.14746094  0.1015625  -0.07128906 -0.07714844\n"," -0.12597656  0.0291748   0.09521484 -0.12402344 -0.109375   -0.12890625\n","  0.16308594  0.28320312 -0.03149414  0.12304688 -0.23242188 -0.09375\n"," -0.12988281  0.0135498  -0.03881836 -0.08251953  0.00897217  0.16308594\n","  0.10546875 -0.13867188 -0.16503906 -0.03857422  0.10839844 -0.10498047\n","  0.06396484  0.38867188 -0.05981445 -0.0612793  -0.10449219 -0.16796875\n","  0.07177734  0.13964844  0.15527344 -0.03125    -0.20214844 -0.12988281\n"," -0.10058594 -0.06396484 -0.08349609 -0.30273438 -0.08007812  0.02099609]\n"],"name":"stdout"}]},{"metadata":{"id":"fJfG5eqA_WBV","colab_type":"text"},"cell_type":"markdown","source":["Q3:  Now using Numpy extract the magnitude (L2 norm) of the vectors  and subtract among the word pairs in Q1. Do the magnitudes of the vectors matter? Justify your answer?\n"]},{"metadata":{"id":"aBRNCnVl_WBX","colab_type":"code","outputId":"8aa51d25-620d-4a6e-bd0c-1d1d681a15ec","executionInfo":{"status":"ok","timestamp":1553548965468,"user_tz":420,"elapsed":390,"user":{"displayName":"Pedro Junior Vicente Valdez","photoUrl":"https://lh5.googleusercontent.com/-dmH1Mj72Wlc/AAAAAAAAAAI/AAAAAAAAAAk/dLWhjPglJRo/s64/photo.jpg","userId":"10490573767420939040"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"cell_type":"code","source":["# np.linalg.norm(model[word], ord=2)\n","\n","for pair in word_pairs:\n","  print(\"{}: {:.4f}, {:.4f}\".format(\n","        pair, \n","        np.linalg.norm(model[pair[0]], ord=2) - np.linalg.norm(model[pair[1]], ord=2), \n","        np.linalg.norm(model[pair[0]] - model[pair[1]], ord=2)))\n","# model[word].shape"],"execution_count":10,"outputs":[{"output_type":"stream","text":["('India', 'Pakistan'): -0.4565, 2.3936\n","('massive', 'puny'): -0.7695, 3.0797\n","('California', 'Sacramento'): -0.5296, 2.5566\n","('Iceland', 'volcano'): -1.0918, 4.2345\n","('fast', 'faster'): -0.3869, 2.6692\n"],"name":"stdout"}]},{"metadata":{"id":"bAasO8ecvY6v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9422d914-7708-44b1-ced4-dd5f3e531698","executionInfo":{"status":"ok","timestamp":1553549110178,"user_tz":420,"elapsed":332,"user":{"displayName":"Pedro Junior Vicente Valdez","photoUrl":"https://lh5.googleusercontent.com/-dmH1Mj72Wlc/AAAAAAAAAAI/AAAAAAAAAAk/dLWhjPglJRo/s64/photo.jpg","userId":"10490573767420939040"}}},"cell_type":"code","source":["np.linalg.norm(model[pair[0]], ord=2)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.513517"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"6Z9XeEv9_WBh","colab_type":"text"},"cell_type":"markdown","source":["Q4: What is the relationship between the magnitude of individual vectors, the vectors themselves and the cosine distance for any pair of words. Choose any tuple in Q1 and provide your answer. \n"]},{"metadata":{"id":"pt23S-T0_WBj","colab_type":"text"},"cell_type":"markdown","source":["It seems like the magnitudes of the vectors don’t matter. There seems to be no direct relationship between the closeness of the words and their L2 norm magnitude.\n","This is because a word (and its respective semantic meaning) is represented by a vector that has length (L2 norm) and direction. When we update the word embeddings during the training phase, we are correcting both the length and direction of the vector. It is therefore possible for us to use cosine similarity and vector subtraction/addition to get words of similar/opposite meanings. Simply doing L2 norm arithmetic will be meaningless because it ignored the critical direction information."]},{"metadata":{"id":"XJefiWTn_WBl","colab_type":"text"},"cell_type":"markdown","source":["Q5: Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following condition   \n","> (King- Queen) <br />\n","> (bigger - big + small ) <br />"]},{"metadata":{"id":"2Vwt3QIH_WBn","colab_type":"code","outputId":"dff002ee-bf2d-497b-8a91-9914dfd9c24b","executionInfo":{"status":"ok","timestamp":1553205142690,"user_tz":420,"elapsed":11719,"user":{"displayName":"Neha Mittal","photoUrl":"","userId":"15029704310197261536"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["print(model.most_similar(positive=[\"king\",\"man\"], negative=[\"queen\"], topn=2))\n","print(model.most_similar(positive=[\"bigger\",\"small\"], negative=[\"big\"], topn=2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"stream","text":["[('boy', 0.5393532514572144), ('guy', 0.47399765253067017)]\n","[('larger', 0.7402471899986267), ('smaller', 0.732999324798584)]\n"],"name":"stdout"}]},{"metadata":{"id":"zuY_PB43_WBx","colab_type":"text"},"cell_type":"markdown","source":["Q6: Explore and come up with a similar analogy that holds for (bigger - big + small )"]},{"metadata":{"id":"mXNQae8l_WBy","colab_type":"code","outputId":"4e1caaa1-8242-481a-b7a4-21a5d0cc7169","executionInfo":{"status":"ok","timestamp":1553149059044,"user_tz":420,"elapsed":170673,"user":{"displayName":"Neha Mittal","photoUrl":"","userId":"15029704310197261536"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["print(model.most_similar(positive=[\"taller\",\"Short\"], negative=[\"tall\"], topn=2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"stream","text":["[('shorter', 0.43716010451316833), ('Long', 0.4175928831100464)]\n"],"name":"stdout"}]}]}